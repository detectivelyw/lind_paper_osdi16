\section{Evaluation}
\label{sec.evaluation}

In order to evaluate Lind's effectiveness in containing untrusted code and
protecting the OS kernel, we compared its performance against seven other existing
virtualization systems -- VirtualBox, VMWare
Workstation, Docker, LXC, QEMU, KVM and Graphene. This section describes
the purpose and setup of our experiments, presents and discusses our experiment results.
We chose these seven systems because they are representative of the most
widely-used design models in different markets.
Among them, VirtualBox and VMWare Workstation are commercial OS VM products, while
LXC and KVM are Linux kernel modules. Docker, QEMU, and Graphene are well-known open
source projects. Lastly, we also compared against Native Linux, which serves as a
baseline for comparison.

Our tests were designed to answer four fundamental questions:

\textit{How does Lind compare to other virtualization systems
in protecting against zero-day Linux kernel bugs?}
(Section~{\ref{Linux-Kernel-Bug-Test-and-Evaluation}})

\textit{How much of the underlying kernel code is exposed, and is thus
vulnerable in different virtualization systems?}
(Section~{{\ref{Reachable-Kernel-Trace-Analysis-for-Different-Virtualization-Systems}})

\textit{If Lind's SafePOSIX construction has bugs, how much of a threat does this pose?}
(Section~{{\ref{Reachable-Kernel-Trace-Analysis-for-Repy-Sandbox}})

\textit{In the Lind prototype, what is the expected performance overhead in
real-world applications?}


\subsection{Linux Kernel Bug Test and Evaluation}
\label{Linux-Kernel-Bug-Test-and-Evaluation}

\textbf{Test Purpose.}
We conducted a set of experiments to evaluate how well each virtualization system protects the Linux kernel 
against reported zero-day bugs.

\noindent
\textbf{Setup.}
We identified and examined a list of 69 historical bugs that have
specifically targeted Linux kernel 3.14.1 \cite{CVE-Datasource}.
By analyzing security kernel patches for those bugs,
we identified the lines of code in the kernel that correspond to each one.

In order to test if a bug could be triggered, we created or located C
code capable of exploiting each of the kernel bugs \cite{Exploit-Database}.
We were only able to trigger and obtain results for 35 out of the 69 bugs in our experiments,
either because of a difficulty in clearly determining if triggering had occurred, or an inability,
at this time, to find code to trigger them. We decided to focus our study on
only these bugs and leave the other, more complex ones, to future work and analysis.

We compiled and ran the exploit C code under each virtualization system to
obtain their kernel traces, and then used our kernel trace safety metric to
determine if a specific bug was triggered.

\noindent
\textbf{Results.}
We found that a substantial number of bugs could be triggered in existing
virtualization systems, as shown in Table \ref{table:trigger_vulnerabilities}.
A full 35 out of 35 (100\%) bugs were triggered in Native Linux,
while the other programs had lower rates: 14/35 (40\%) in
VirtualBox,
11/35 (31.4\%)  in VMWare Workstation, 8/35 (22.9\%)  in Docker,
12/35 (34.3\%)  in LXC, 5/35 (14.3\%)  in QEMU, 5/35 (14.3\%)  in KVM,
and 8/35 (22.9\%) bugs in Graphene.
In comparison, only 1 out of 35 bugs  (2.9\%) was triggered in Lind.

To better understand these results,
we take a closer look at four
vulnerabilities from Table \ref{table:trigger_vulnerabilities}. 
The four cases here represent the distinctive scenarios where bugs show 
different behaviors in different security systems. 
These short case
studies show how different system design philosophies can have
different security impacts.

\begin{table*}[!ht]
\scriptsize
\centering

\caption {\small Linux Kernel Bugs, and Vulnerabilities in Different Virtualization Systems
({\color{red}\ding{51}}: vulnerability triggered;
{\color{blue}\ding{51}}: vulnerability triggered with Guest Additions; \ding{55}: vulnerability
not triggered).}

\begin{tabular}{|p{1.7cm}|l|l|p{1cm}|p{1cm}|p{.8cm}|p{1cm}|p{.8cm}|p{1cm}|p{.8cm}|}\hline

\multirow{2}{1.7cm}{\bf Vulnerability}    &  \multirow{2}{.7cm}{\bf Native Linux}  &  \multirow{2}{*}{\bf VirtualBox}
&  \multirow{2}{.7cm}{\bf VMWare}
 & \multirow{2}{1cm}{\bf Docker} & \multirow{2}{1cm}{\bf LXC} &
\multirow{2}{1cm}{\bf QEMU} & \multirow{2}{1cm}{\bf KVM} &
\multirow{2}{1cm}{\bf Graphene} & \multirow{2}{1cm}{\bf Lind} \\
& & & & & & & & & \\
\hline

 CVE-2015-5706 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{blue}\ding{51}} &
\multirow{1}{1cm}{{\color{blue}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55}  \\

 CVE-2015-0239 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-9584 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55}& \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-9529 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55}& \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-9322 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}}  &
\ding{55}  & \multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}
\\

 CVE-2014-9090 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-8989 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55}  \\

 CVE-2014-8559 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-8369 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-8160 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-8134 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}
\\

 CVE-2014-8133 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \ding{55} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-8086 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{blue}\ding{51}} &
\multirow{1}{1cm}{{\color{blue}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55} & \ding{55}  \\

 CVE-2014-7975 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-7970 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-7842 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-7826 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \ding{55}  &
\ding{55} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}
\\

 CVE-2014-7825 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \ding{55} &
\ding{55} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}
\\

 CVE-2014-7283 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-5207 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-5206 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
\multirow{1}{1cm}{{\color{red}\ding{51}}}  & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}
\\

 CVE-2014-5045 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-4943 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-4667 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}  \\

 CVE-2014-4508 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-4171 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}}  \\

 CVE-2014-4157 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-4014 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
\multirow{1}{1cm}{{\color{red}\ding{51}}}  & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}
\\

 CVE-2014-3940 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{blue}\ding{51}}  &
\ding{55}  & \multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-3917 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \ding{55} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-3153 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
  \ding{55}  & \ding{55} & \ding{55} &
  \ding{55} & \ding{55} &
  \ding{55}  & \ding{55}  \\

 CVE-2014-3144 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-3122 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-2851 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-0206 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &  \ding{55}  & \ding{55}  \\
\hline

 {\bf Vulnerabilities Triggered} & \multirow{2}{1cm}{\bf 35/35 (100\%)} & {\bf 14/35 (40.0\%)} &
 {\bf 11/35 (31.4\%)}  & {\bf 8/35 (22.9\%)} & {\bf 12/35 (34.3\%)} & {\bf 5/35 (14.3\%)} & {\bf 5/35 (14.3\%)} &
 {\bf 8/35 (22.9\%)}  & {\bf 1/35 (2.9\%)}  \\
\hline
\end{tabular}
\label{table:trigger_vulnerabilities}
\end{table*}


\emph{\textbf{All systems vulnerable.}}  Representative bug: CVE-2014-4171. 
This is the only vulnerability in our test that was triggered in every
system, including Lind. It resides inside the \texttt{mm/shmem.c} kernel path and
can be triggered by using \texttt{mmap()} system call to access a hole in the memory.
The \texttt{mmap()} call then invokes \texttt{shmem\_fault()}, which will cause contention
on \texttt{i\_mmap\_mutex}, and lead to a serious starvation of memory resource.

The reason that Lind triggered this bug is because \texttt{mmap()} cannot easily
be safely reimplemented inside our SafePOSIX API. The call sets up a
memory region where the OS will later
intervene and automatically convert all accesses into ones that reach the
underlying file.  The code does not explicitly make system calls, and as
a result, with Lind's design we cannot intercept those accesses and call through
the Repy sandbox kernel. Thus,
Lind allows \texttt{mmap()} calls to directly access the kernel, which
opens the chance to trigger this vulnerability.

In the library OS system Graphene, similar to Lind, it does not reimplement the
\texttt{mmap()} system call in its library module \texttt{libLinux}. Instead, when doing
memory allocation operations like \texttt{malloc()} and \texttt{brk()}, Graphene will
pass down those system calls to the underlying kernel, and rely on the kernel to
perform the \texttt{mmap()} system function.
KVM and LXC both reside inside the Linux kernel and inherit the \texttt{mmap()} system function
from the kernel. QEMU is built on KVM, and relies on the KVM module to perform \texttt{mmap()}
function. Docker is built on LXC, which relies on the LXC module to perform \texttt{mmap()}
function. In VirtualBox and VMWare Workstation, the OS VM has its own mechanism to
do memory management. During the initial setup, the OS VM needs to request memory resource
by making \texttt{mmap()} to the host kernel. In addition, during the runtime of the VM process,
when there is excessive memory usage, or reconfiguration of memory allocation, the VM kernel module
will attempt to call \texttt{mmap()} to the host kernel. Thus, this vulnerability related with \texttt{mmap()}
is exploitable under the virtualization systems that we tested.

\emph{\textbf{Only Native Linux vulnerable.}}  Representative bug: CVE-2014-5045.
This vulnerability was only triggered inside Native Linux. It resides in the
\texttt{fs/namei.c} kernel path and was triggered because
the \texttt{mountpoint\_last()}
%\texttt{mountpoint\_last(struct nameidata *nd, struct path *path)}
function does not properly
maintain a reference count during attempts to use the \texttt{umount()} system call,
in conjunction with a symbolic link. Unmounting from a symbolic link could block
another unmount operation, and allow attackers to cause a denial of service or
deploy use-after-free exploitation. 

Lind does not implement symbolic link, but
even similar functionality that might be risky is implemented entirely
within its SafePOSIX module. The bug would (at most) enable an attacker to execute
code within the Repy sandbox and would not harm other parts of the system.

Graphene does not implement symbolic link in its Linux system call API, and thus avoids
this problem.
OS VM like VirtualBox and VMWare Workstation have their own metadata to maintain their file
directories and symbolic links, which do not directly rely on the host OS.
%\cappos{Why did the flag in the first example
%work then?  Also, why doesn't this exist in Docker / LXC?}
Furthermore, symbolic links in those systems will be contained within the virtualization system's image,
and will not be able to reach the underlying host OS. In this case, those virtualization systems provide enough
isolation to prevent this bug.
Docker/LXC and QEMU/KVM happen to avoid this bug because their kernel module modified the Linux kernel
that fixed this problem. It should be noted though that by their design model, they both tend to suffer from
the same vulnerabilities that exist inside the Native Linux kernel.

\emph{\textbf{Some systems safe, some systems vulnerable.}}  Representative bug: CVE-2014-8086.
This vulnerability was not triggered inside Graphene and Lind, but was triggered inside
VirtualBox, VMWare workstation, Docker, and Native Linux. It resides in
the \texttt{fs/ext4/file.c} kernel path, and can be triggered by a file system write
function call, made together with \texttt{fcntl} function call
with argument \texttt{F\_SETFL}, and \texttt{O\_DIRECT} flag. If triggered, it could
allow attackers to cause a denial of service (file unavailability). Both Lind and
Graphene prevented this bug, but for different reasons. Lind
implements \texttt{fcntl} in SafePOSIX, so the underlying kernel is not called.
Graphene checks and blocks certain system calls, including
a \texttt{fcntl} system call with the \texttt{O\_DIRECT} flag.
Other systems like VirtualBox, VMWare Workstation, Docker, and Native Linux,
all suffer from this vulnerability because calls go directly into the host OS
kernel.

\emph{\textbf{Only Lind safe.}}  Representative bug: CVE-2015-5706. As
shown in our results, this vulnerability was triggered in every
virtualization system we tested, except Lind. This vulnerability
is closely related to file system calls and file flags, resides in the \texttt{fs/namei.c}
kernel path, and can be triggered by making a \texttt{path\_openat()} function
call with file flag \texttt{O\_TMPFILE}. \texttt{path\_openat()} will jump to the wrong
place after \texttt{do\_tmpfile()}, and do \texttt{path\_cleanup()} twice. This would
allow local users to perform use-after-free exploitation to cause a denial of service.
This bug was not triggered in Lind, because it does not support the use of the
\texttt{O\_TMPFILE} file flag. In fact, the only call in the Repy sandbox that
opens a file does not take an argument for flags or other operations.  The
only arguments it takes are a filename (that must consist of a small number
of highly restricted characters) and a flag to indicate whether a file should
be created if one does not exist.
Other virtualization systems allow more complex configuration of flags to
pass through to the underlying OS kernel.
%\cappos{Why does VirtualBox pass this
%through?  My VirtualBox file system is a single VDI file.  How does this end
%up calling into the host OS's kernel and why?}  \cappos{Does this vary
%if you use a different FS type on VirtualBox?}
In this case, the \texttt{O\_TMPFILE} file flag was
allowed in Native Linux, VirtualBox, VMWare Workstation, Docker, and Graphene.

Our initial results, as illustrated by the above case studies, suggest
that bugs are usually triggered by complex system calls,or basic system calls
with complicated or rarely used flags. The \emph{Lock-in-Pop} design on which Lind is based,
which provides strictly controlled access to the kernel, poses
the least risk of triggering bugs. Our next step was to compare exactly how
much kernel access, and therefore, potential risk, was possible in systems not
using our design metric.


\subsection{Comparison of Kernel Code Exposure in Different Virtualization
Systems}
\label{Reachable-Kernel-Trace-Analysis-for-Different-Virtualization-Systems}

\begin{table}
\centering
\scriptsize
\caption{\small Reachable kernel trace analysis for different virtualization
systems.}
\begin{tabular}{|l|l|l|l|}
  \hline
  \multirow{3}{1.5cm}{\bf Virtualization system} & \multicolumn{3}{c|}{\bf Kernel trace} \\ \cline{2-4}
  & \multirow{2}{1.5cm}{Compared to native Linux} & \multirow{2}{1.5cm}{In popular paths} & \multirow{2}{1cm}{In risky paths} \\
  & & & \\  \hline
  VirtualBox & 78.8 \% & 46.5 \% & 53.5 \% \\
  \hline
  \multirow{2}{1.5cm}{VMWare Workstation} & \multirow{2}{*}{72.6 \%} &
  \multirow{2}{*}{50.2 \%} & \multirow{2}{*}{49.8 \%} \\
  & & & \\   \hline
  Docker & 61.3 \% & 58.4 \% & 41.6 \% \\
  \hline
  LXC &  65.6\% &  55.7\% &  44.3\% \\
  \hline
   QEMU &  70.1\% & 61.2 \% &  38.8\% \\
  \hline
   KVM &  75.4\% &  57.0\% &  43.0\% \\
  \hline
  Graphene & 49.2 \% & 65.1 \% & 34.9 \% \\
  \hline
  Lind & 36.2 \% & 100 \% & 0 \% \\
  \hline
\end{tabular}
\label{table:trace-systems}
\end{table}

\textbf{Test Purpose.}
We conducted a set of system call fuzzing experiments in each virtualization system to 
see how much of the underlying kernel would be executed and exposed. This helps us 
understand the potential risks a virtualization system may pose based upon the way it allows 
access to the kernel code.  

\noindent
\textbf{Setup.}
To analyze the reachable kernel paths for each
virtualization system,
we conducted system call fuzzing with Trinity (similar to our approach in Section~{\ref{sec.metric}}) to obtain
the kernel trace in each system.
All experiments were conducted under Linux kernel 3.14.1.

\noindent
\textbf{Results.}
We obtained the total reachable kernel trace for
each tested system,
and further analyzed the components of those traces. These results
are shown in Table \ref{table:trace-systems}.

As shown in the table, Lind accessed the least amount of code in the OS
kernel. More importantly,
all the kernel code it accessed was in the ``safe'' portion, the
commonly used kernel paths.
A large portion of the kernel paths accessed by Lind lie in
\texttt{fs/} to perform file system operations.
In Lind, only basic function calls,
like \texttt{open()}, \texttt{close()}, \texttt{read()}, \texttt{write()}, \texttt{mkdir()},
\texttt{rmdir()}, are allowed. In addition, only commonly used flags are allowed. For example,
only \texttt{O\_CREAT}, \texttt{O\_EXCL}, \texttt{O\_APPEND}, \texttt{O\_TRUNC},
\texttt{O\_RDONLY}, \texttt{O\_WRONLY}, and \texttt{O\_RDWR} are permitted for \texttt{open()}.

As a result, the reachable kernel trace we obtained with Lind is from the safe
portion of the kernel, which contains fewer bugs
as verified in Section~{\ref{Verification-of-Hypothesis}}.

The other virtualization systems all accessed a substantial number of code
paths in the kernel,
and they all accessed a larger section of the risky portion.
This is because they have
more dependence on many complex system function calls, and
allow extensive use of complicated flags. For example,
Graphene provides a complex system call API that allows
\texttt{fork()} and \texttt{signals}, which can access many risky lines of code.
VirtualBox, VMWare Workstation, and Docker have even larger
code base and more complicated system functions. They allow
rarely used flags, such as \texttt{O\_TMPFILE}, \texttt{O\_NONBLOCK},
and \texttt{O\_DSYNC}, which can reach potentially dangerous lines
of code.

Based on our hypothesis, many historical bugs, as well as undetected
zero-day bugs, could be located in the uncommonly used kernel paths.
Thus, accessing the risky portion without restriction is dangerous, and
leads to potential kernel bug exploitation. The results in Table
\ref{table:trace-systems} verify our hypothesis.

To summarize, our analysis signals that Lind triggers the fewest kernel bugs because
it has better control over the access to the OS kernel.


\subsection{Impact of Potential Vulnerabilities in Lind's SafePOSIX Construction}
\label{Reachable-Kernel-Trace-Analysis-for-Repy-Sandbox}

\textbf{Test Purpose.}
We want to understand what potential risks could be posed if Lind's SafePOSIX construction 
has vulnerabilities.

\noindent
\textbf{Setup.}
Since we needed to see what portion of the kernel could be reached by
leveraging the Repy sandbox kernel, we conducted system call fuzzing with Trinity
to obtain the reachable kernel trace in Linux kernel 3.14.1.

\noindent
\textbf{Results.}
An important question about Lind's security properties is what would happen if there is a bug or a failure in Lind's TCB,
the Repy sandbox kernel?

The results are shown in Table \ref{table:trace-Repy}. The trace of Repy is
slightly larger (5.8\%) than that of Lind.
Repy's design can not allow attackers or bugs to
have more access to the risky paths in the OS kernel, and only a small amount (5.8\%) of
additional common paths in the OS kernel might be open.
Those new kernel paths are added because some functions in Repy
have more capabilities for message sending and network connecting than the system call interfaces
provided by Lind. For example, in Repy,
\texttt{sendmessage()} and \texttt{openconnection()}
functions could reach out to more lines of code when fuzzed. However, the kernel
 trace of Repy still lies completely within the safe
portion of the OS kernel.
Since the safe portion contains fewer kernel bugs, the Repy sandbox kernel
will have a very slim chance to trigger OS kernel bugs.

The results explained above shows that even if our Repy sandbox kernel has a
bug or failure inside,
it only slightly increases the amount of OS kernel paths open to attacks,
and all these paths accessed are still inside the safe portion.
Therefore, Repy will not grant attackers more opportunities to trigger OS
kernel bugs.
Since Repy, arguably the main security weakness of the system, can be
considered safe through our analysis,
it shows that Lind has the potential to provide strong security to run user applications.

\begin{table}
\centering
\scriptsize
\caption{\small Comparison of reachable kernel traces within Repy sandbox kernel and Native Linux.}
\begin{tabular}{|l|l|l|l|l|}
  \hline
  \multirow{3}{.8cm}{\bf Sandbox} & \multicolumn{4}{c|}{\bf Kernel trace} \\ \cline{2-5}
  & \multirow{2}{1cm}{Compared to Lind} &
  \multirow{2}{1.3cm}{Compared to native Linux} & \multirow{2}{1.5cm}{In popular paths} &
  \multirow{2}{1.0cm}{In risky paths} \\
  & & & & \\  \hline

  Repy & 105.8 \% & 38.3 \% & 100 \%  & 0 \%  \\
  \hline
\end{tabular}
\label{table:trace-Repy}
\end{table}


\subsection{Performance Overhead Evaluation}
\label{Performance-Evaluation}

\textbf{Test Purpose.}
We evaluated Lind to see
what is its execution time performance overhead compared to Native Linux when running real-world applications.
Note that we did not optimize the performance of Lind in any way before running
these tests.

\noindent
\textbf{Setup.}
To test the execution time overhead in Lind for running real-world applications,
we first compiled and ran six widely used legacy applications:
a prime number calculator Primes version 1.0, 
GNU Grep version 2.9, GNU Wget version 1.13, GNU Coreutils version 8.9, 
GNU Netcat version 0.7.1, and K\&R Cat.

All ran unaltered and correctly inside Lind. The source code of each of the applications remained
unmodified. To run the applications, it was sufficient to just recompile the
source code using NaCl's compiler and Lind's \texttt{glibc} to call
into SafePOSIX.

In addition, we ran large legacy applications, Tor version 0.2.3 and Apache version 2.0.64 in Lind. 
Both Tor and Apache were recompiled with NaCl's compiler and ran in Lind.
We used Tor's built-in benchmark program and Apache benchmarking tool \texttt{ab} to perform 
basic testing operations and record the execution time.

\noindent
\textbf{Results.}
Table \ref{table:performance_apps} shows the execution time performance
results for running six real-world applications, the primes calculator Primes, GNU Grep, 
GNU Wget, GNU Coreutils, GNU Netcat, and K\&R Cat.
The Primes application run in Lind has a 6\% performance overhead compared to
Native Linux. CPU bound applications, like the Primes, engender little overhead,
because they run only inside the NaCl computation sandbox. No system calls are required,
and there is no need to go through the safe POSIX interface. The small amount of overhead
is generated by NaCl's instruction alignment at building time. Another reason for the overhead
is that the instructions built by NaCl have a higher rate of cache misses, which can slowdown the
program. We expect other CPU bound processes to behave similarly.

The other five applications experienced slowdowns roughly ranged from 3x to 6x.
Since they are all I/O heavy applications,
each repeatedly calls into the SafePOSIX code which then reimplements
the call.  The additional computation of SafePOSIX produced the additional
overhead. We have not conducted any performance optimization for Lind.
As we focus on the security aspect first, we leave that to future work. 
It should be noted that for the six applications that we tested, even with the current overhead, 
Lind managed to control the performance slowdown to a level that is barely noticeable to the users. 
The fact that the total execution time was limited to the magnitude of 10000 ms ensures that 
user experience is still good. 

A summary of the results for Tor is shown in Table \ref{table:performance_tor}. The
benchmarks focus on cryptographic operations,
which are CPU intensive, but also make system calls like \texttt{getpid}, and reads to
\texttt{/dev/urandom}.
The digest operations time the access of a map of message digests.
The AES operations time AES encryptions of several sizes and message
digest creation.
Cell processing executes full packet encryption and decryption. In our
test, Lind slowed down these operations by 2.5x to 5x. We believe these
slowdowns are due to the increased code size produced by NaCl,
%\cappos{I'm not sure why this would be.  Does NaCl show this too?}
and the increased overhead from Lind's SafePOSIX system call interface.

Results for Apache benchmarking tool \texttt{ab} is presented in Table \ref{table:performance_apache}. 
In the set of experiments we conducted, Lind produced a performance slowdown roughly 
ranged from 2x to 10x. Most of the overhead was incurred due to system call operations inside the 
SafePOSIX construction. 

As shown above, Lind generally incurs some performance overhead. 
However, it is fair to say that performance slowdown is common in virtualization systems. 
For example, a research prototype Graphene \cite{Graphene-14} also shows overhead ranged roughly from 
40\% to 2x, when running applications such as Apache and UNIX benchmark. 
And Lind has the same magnitude of slowdown with Graphene in many cases. 
It should be noted that, we have not yet attempted to optimize its performance.
However, since an attack on the kernel can have devastating
consequences, %at this initial stage,
a tradeoff between security and performance could be justified.
The fact that Lind is able to run
%\cappos{4 applications isn't many...
%Do we have Apache numbers or something else to quantify?}
%\yiwen{I am looking at more apps and libs that we can run and test in Lind.}
legacy applications
suggests that it
is a positive step towards building new secure systems.

\begin{table}
\centering
\scriptsize
\caption{\small Execution time performance results on six real-world applications: Native
Linux vs. Lind.}
\begin{tabular}{|r|r|r|r|}
  \hline
  {\bf Application} & {\bf Native Code} & {\bf Lind} & {\bf Impact}  \\
  \hline
  Primes & 10000 ms & 10600 ms & 1.06x \\
  GNU Grep & 65 ms & 260 ms & 4.00x \\
  GNU Wget & 25 ms & 96 ms & 3.84x \\
  GNU Coreutils & 275 ms & 920 ms & 3.35x \\
  GNU Netcat & 780 ms & 2180 ms & 2.79x \\
  K\&R Cat & 20 ms & 125 ms & 6.25x \\
  \hline
\end{tabular}
\label{table:performance_apps}
\end{table}

\begin{table}
\centering
\scriptsize
\caption{\small Performance results on Tor's built-in benchmark program: Native
Linux vs. Lind.}
\begin{tabular}{|r|r|r|r|}
  \hline
  {\bf Benchmark} & {\bf Native Code} & {\bf Lind} & {\bf Impact}  \\
  \hline
  Digest Tests: & & & \\
  Set & 54.80 nsec/element & 176.86 nsec/element & 3.22x \\
  Get & 42.30 nsec/element & 134.38 nsec/element & 3.17x \\
  Add & 11.69 nsec/element & 53.91 nsec/element & 4.61x \\
  IsIn & 8.24 nsec/element & 39.82 nsec/element & 4.83x \\
  \hline
  AES Tests: & & & \\
  1 Byte & 14.83 nsec/B & 36.93 nsec/B & 2.49x \\
  16 Byte & 7.45 nsec/B & 16.95 nsec/B & 2.28x \\
  1024 Byte & 6.91 nsec/B & 15.42 nsec/B & 2.23x \\
  4096 Byte & 6.96 nsec/B & 15.35 nsec/B & 2.21x \\
  8192 Byte & 6.94 nsec/B & 15.47 nsec/B & 2.23x \\
  Cell Sized & 6.81 nsec/B & 14.71 nsec/B & 2.16x \\
  \hline
  Cell Processing: & & & \\
  Inbound & 3378.18 nsec/cell & 8418.03 nsec/cell & 2.49x \\
  (per Byte) & 6.64 nsec/B & 16.54 nsec/B & - \\
  Outbound & 3384.01 nsec/cell & 8127.42 nsec/cell & 2.40x \\
  (per Byte) & 6.65 nsec/B & 15.97 nsec/B & - \\
  \hline
\end{tabular}
\label{table:performance_tor}
\end{table}

\begin{table}
\centering
\scriptsize
\caption{\small Performance results on Apache benchmarking tool \texttt{ab}: Native
Linux vs. Lind.}
\begin{tabular}{|r|r|r|r|}
  \hline
  {\bf \# of Requests} & {\bf Native Code} & {\bf Lind} & {\bf Impact}  \\
  \hline
  10 & 900 ms & 1700 ms & 1.89x \\
  20 & 1600 ms & 5000 ms & 3.13x \\
  50 & 4800 ms & 30000 ms & 6.25x\\
  100 & 10000 ms & 92000 ms & 9.20x\\
  \hline
\end{tabular}
\label{table:performance_apache}
\end{table}