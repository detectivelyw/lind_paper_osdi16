\section{Evaluation}
\label{sec.evaluation}

To evaluate Lind's effectiveness, 
%in containing untrusted code and protecting the OS kernel, 
we compared its performance against seven existing
virtualization systems -- VirtualBox, VMWare
Workstation, Docker, LXC, QEMU, KVM and Graphene. 
%This section describes
%the purpose and setup of our experiments, and presents and discusses our results.
We chose these seven systems because they are representative of the most
widely-used design models in different markets.
Among them, VirtualBox and VMWare Workstation are commercial OS VM products, while
LXC and KVM are Linux kernel modules. Docker, QEMU, and Graphene are well-known open
source projects. Lastly, we also tested Native Linux to serve as a
baseline for comparison.
%
Our tests were designed to answer four fundamental questions:

\textit{How does Lind compare to other virtualization systems
in protecting against zero-day Linux kernel bugs?}
(Section~{\ref{Linux-Kernel-Bug-Test-and-Evaluation}})

\textit{How much of the underlying kernel code is exposed, and is thus
vulnerable in different virtualization systems?}
(Section~{{\ref{Reachable-Kernel-Trace-Analysis-for-Different-Virtualization-Systems}})

\textit{If Lind's SafePOSIX construction has bugs, how much threat does this pose?}
(Section~{{\ref{Reachable-Kernel-Trace-Analysis-for-Repy-Sandbox}})

\textit{In the Lind prototype, what is the expected performance overhead in
real-world applications?}


\subsection{Linux Kernel Bug Test and Evaluation}
\label{Linux-Kernel-Bug-Test-and-Evaluation}

%\textbf{Test Purpose.} 
%To evaluate how well each virtualization system protects the Linux kernel
%against reported zero-day bugs.

\noindent
\textbf{Setup.}
To evaluate how well each virtualization system protects the Linux kernel
against reported zero-day bugs, 
we identified and examined a list of 69 historical bugs that have
targeted Linux kernel 3.14.1 \cite{CVE-Datasource}.
By analyzing security kernel patches for those bugs,
we identified the lines of code in the kernel that correspond to each one.

To test if a bug could be triggered, we created or located C
code capable of exploiting each kernel bug \cite{Exploit-Database}.
We were only able to trigger and obtain results for 35 out of the 69 bugs in our experiments,
either because of a difficulty in clearly determining if triggering had occurred, or an inability,
at this time, to find code to trigger them. We decided to focus our study on
only these bugs and leave the complex ones to future work and analysis.

We compiled and ran the exploit C code under each virtualization system to
obtain their kernel traces, and then used our kernel trace safety metric to
determine if a specific bug was triggered.

\begin{table*}[!ht]
\scriptsize
\centering

\begin{tabular}{|p{1.7cm}|l|l|p{1cm}|p{1cm}|p{.8cm}|p{1cm}|p{.8cm}|p{1cm}|p{.8cm}|}\hline

\multirow{2}{1.7cm}{\bf Vulnerability}    &  \multirow{2}{.7cm}{\bf Native Linux}  &  \multirow{2}{*}{\bf VirtualBox}
&  \multirow{2}{.7cm}{\bf VMWare}
 & \multirow{2}{1cm}{\bf Docker} & \multirow{2}{1cm}{\bf LXC} &
\multirow{2}{1cm}{\bf QEMU} & \multirow{2}{1cm}{\bf KVM} &
\multirow{2}{1cm}{\bf Graphene} & \multirow{2}{1cm}{\bf Lind} \\
& & & & & & & & & \\
\hline

 CVE-2015-5706 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{blue}\ding{51}} &
\multirow{1}{1cm}{{\color{blue}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55}  \\

 CVE-2015-0239 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-9584 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55}& \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-9529 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55}& \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-9322 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}}  &
\ding{55}  & \multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}
\\

 CVE-2014-9090 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-8989 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55}  \\

 CVE-2014-8559 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-8369 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-8160 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-8134 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}
\\

 CVE-2014-8133 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \ding{55} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-8086 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{blue}\ding{51}} &
\multirow{1}{1cm}{{\color{blue}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55} & \ding{55}  \\

 CVE-2014-7975 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-7970 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-7842 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-7826 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \ding{55}  &
\ding{55} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}
\\

 CVE-2014-7825 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \ding{55} & \ding{55} &
\ding{55} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}
\\

 CVE-2014-7283 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-5207 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-5206 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
\multirow{1}{1cm}{{\color{red}\ding{51}}}  & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}
\\

 CVE-2014-5045 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-4943 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-4667 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} & \multirow{1}{1cm}{{\color{red}\ding{51}}}  & \ding{55}  \\

 CVE-2014-4508 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-4171 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}}  \\

 CVE-2014-4157 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-4014 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
\multirow{1}{1cm}{{\color{red}\ding{51}}}  & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}
\\

 CVE-2014-3940 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{blue}\ding{51}}  &
\ding{55}  & \multirow{1}{1cm}{{\color{red}\ding{51}}} & \multirow{1}{1cm}{{\color{red}\ding{51}}} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-3917 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & {\color{red}\ding{51}}  &
\ding{55}  & \ding{55} & \ding{55} &
\ding{55} & \ding{55} &
\ding{55}  & \ding{55}  \\

 CVE-2014-3153 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
  \ding{55}  & \ding{55} & \ding{55} &
  \ding{55} & \ding{55} &
  \ding{55}  & \ding{55}  \\

 CVE-2014-3144 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-3122 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-2851 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &
 \ding{55}  & \ding{55}  \\

 CVE-2014-0206 & \multirow{1}{.7cm}{{\color{red}\ding{51}}} & \ding{55}  &
 \ding{55}  & \ding{55} & \ding{55} &
 \ding{55} & \ding{55} &  \ding{55}  & \ding{55}  \\
\hline

 {\bf Vulnerabilities Triggered} & \multirow{2}{1cm}{\bf 35/35 (100\%)} & {\bf 14/35 (40.0\%)} &
 {\bf 11/35 (31.4\%)}  & {\bf 8/35 (22.9\%)} & {\bf 12/35 (34.3\%)} & {\bf 5/35 (14.3\%)} & {\bf 5/35 (14.3\%)} &
 {\bf 8/35 (22.9\%)}  & {\bf 1/35 (2.9\%)}  \\
\hline
\end{tabular}

\caption {\small Linux Kernel Bugs, and Vulnerabilities in Different Virtualization Systems
({\color{red}\ding{51}}: vulnerability triggered;
{\color{blue}\ding{51}}: vulnerability triggered with guest additions; \ding{55}: vulnerability
not triggered).}

\label{table:trigger_vulnerabilities}
\end{table*}

\noindent
\textbf{Results.}
We found that a substantial number of bugs could be triggered in existing
virtualization systems, as shown in Table \ref{table:trigger_vulnerabilities}.
All (100\%) bugs were triggered in Native Linux,
while the other programs had lower rates: 14/35 (40\%) in
VirtualBox,
11/35 (31.4\%)  in VMWare Workstation, 8/35 (22.9\%)  in Docker,
12/35 (34.3\%)  in LXC, 5/35 (14.3\%)  in QEMU, 5/35 (14.3\%)  in KVM,
and 8/35 (22.9\%) bugs in Graphene.
In comparison, only 1 out of 35 bugs  (2.9\%) was triggered in Lind.

To better understand these results, we take a closer look at four
vulnerabilities from Table \ref{table:trigger_vulnerabilities}.
The four cases described below show how the behaviors of bugs varied
from system to system. These short case
studies demonstrate how the implementation of a system design can
affect security in different ways. \yanyan{do we need to replace all 
reimplementation in the following text?}

\emph{\textbf{All systems vulnerable.}}  Representative bug: CVE-2014-4171.
This is the only vulnerability in our test that was triggered in every
system, including Lind. It resides inside the \texttt{mm/shmem.c} kernel path and
can be triggered by using \texttt{mmap()} system call to access a hole in the memory.
The \texttt{mmap()} call then invokes \texttt{shmem\_fault()}, which will cause contention
on \texttt{i\_mmap\_mutex}, and lead to a serious starvation of memory resources.

We propose that Lind triggered this bug because \texttt{mmap()} cannot easily
be safely reimplemented inside our SafePOSIX API. The call sets up a
memory region where the OS will later
intervene and automatically convert all accesses into ones that reach the
underlying file.  The code does not explicitly make system calls, and as
a result, with Lind's design we cannot intercept those accesses and call through
the Repy sandbox kernel. Thus,
Lind allows \texttt{mmap()} calls to directly access the kernel, which
opens the chance to trigger this vulnerability.

Graphene, similar to Lind, does not reimplement the
\texttt{mmap()} system call in its library module \texttt{libLinux}. Instead, when doing
memory allocation operations like \texttt{malloc()} and \texttt{brk()}, Graphene will
pass those system calls to the underlying kernel, and rely on it to
perform \texttt{mmap()}.
KVM and LXC both reside inside the Linux kernel and inherit \texttt{mmap()} 
from the kernel. QEMU is built on KVM, and so also relies on the KVM module to perform 
\texttt{mmap()}. Similarly, Docker, built on LXC, relies on the native Linux kernel to perform 
\texttt{mmap()}. In VirtualBox and VMWare Workstation, the OS VM has its own mechanism 
for memory management. During the initial setup, the OS VM needs to request memory resource
by making \texttt{mmap()} to the host kernel. Additionally, during the runtime of the VM process,
when there is excessive memory usage, or reconfiguration of memory allocation, the VM kernel module
will attempt to call \texttt{mmap()} to the host kernel. Thus, this \texttt{mmap()} vulnerability
is exploitable under all the virtualization systems that we tested.

\emph{\textbf{Only Native Linux vulnerable.}}  Representative bug: CVE-2014-5045.
This vulnerability was only triggered in Native Linux. It resides in the
\texttt{fs/namei.c} kernel path and was triggered because
the \texttt{mountpoint\_last()}
%\texttt{mountpoint\_last(struct nameidata *nd, struct path *path)}
function does not properly
maintain a reference count during attempts to use the \texttt{umount()} system call,
in conjunction with a symbolic link. Unmounting from a symbolic link could block
another unmount operation, and allow attackers to cause a denial of service or
deploy use-after-free exploitation.

Lind does not implement symbolic link, but
even similar functionality that might be risky is implemented entirely
within its SafePOSIX module. The bug would (at most) enable an attacker to execute
code in the Repy sandbox and would not harm other parts of the system.

Graphene does not implement symbolic link in its Linux system call API, and thus avoids
this problem.
OS VM like VirtualBox and VMWare Workstation have their own metadata to maintain their file
directories and symbolic links, which do not directly rely on the host OS.
%\cappos{Why did the flag in the first example
%work then?  Also, why doesn't this exist in Docker / LXC?}
Furthermore, symbolic links in those systems are contained within the virtualization system's image,
and are not able to reach the underlying host OS. In this case, those virtualization systems provide enough
isolation to prevent this bug.
Docker/LXC and QEMU/KVM happen to avoid this bug because their kernel module modified the Linux kernel
that fixed this problem. It should be noted that by their design model, they both tend to suffer from
the same vulnerabilities that exist in Native Linux.

\emph{\textbf{Some systems safe, some systems vulnerable.}}  Representative bug: CVE-2014-8086.
This vulnerability was not triggered in Graphene or Lind, but was triggered in
VirtualBox, VMWare workstation, Docker, and Native Linux. It was one of several
bugs (i.e. CVE-2014-7826 and CVE-2014-5206) that were triggered in just a few systems.
CVE-2014-8086 resides in the \texttt{fs/ext4/file.c} kernel path, and can be
triggered when a file system \texttt{write}
call is made together with \texttt{fcntl}, 
using argument \texttt{F\_SETFL} and \texttt{O\_DIRECT} flag. If triggered, it could
allow attackers to cause a denial of service (file unavailability). Both Lind and
Graphene prevented this bug, but for different reasons. Lind
implements \texttt{fcntl} in SafePOSIX, so the underlying kernel is not called.
Graphene checks and blocks certain system calls, including
\texttt{fcntl} with the \texttt{O\_DIRECT} flag.
Other systems like VirtualBox, VMWare Workstation, Docker, and Native Linux,
all suffer from this vulnerability because calls go directly into the host OS
kernel.

\emph{\textbf{Only Lind safe.}}  Representative bug: CVE-2015-5706. 
This vulnerability was triggered in every virtualization system we tested except Lind, 
and is closely related to file system calls and file flags. It resides in the \texttt{fs/namei.c}
kernel path, and can be triggered by making a \texttt{path\_openat()} 
call with flag \texttt{O\_TMPFILE}. \texttt{path\_openat()} will jump to the wrong
place after \texttt{do\_tmpfile()}, and do \texttt{path\_cleanup()} twice. This would
allow local users to perform use-after-free exploitation to cause a denial of service.
This bug was not triggered in Lind, because it does not support the use of the
\texttt{O\_TMPFILE} flag. In fact, the only call in the Repy sandbox that
opens a file does not take an argument for flags or other operations.  The
only arguments allowed are a filename (that must consist of a small number
of highly restricted characters) and a flag to indicate whether a file should
be created if one does not exist.
Other virtualization systems allow more complex configuration of flags to
pass to the underlying OS kernel.
%\cappos{Why does VirtualBox pass this
%through?  My VirtualBox file system is a single VDI file.  How does this end
%up calling into the host OS's kernel and why?}  \cappos{Does this vary
%if you use a different FS type on VirtualBox?}
In this case, the \texttt{O\_TMPFILE} file flag was
allowed in Native Linux, VirtualBox, VMWare Workstation, Docker, and Graphene.

Our initial results % as illustrated by the above case studies, 
suggest that bugs are usually triggered by complex system calls, or basic system calls
with complicated or rarely used flags. The \emph{Lock-in-Pop} design, and thus Lind,
provides strictly controlled access to the kernel, poses
the least risk of triggering bugs. Our next step was to compare exactly how
much kernel access, or potential risk, was possible in systems not
using our design metric.


\subsection{Comparison of Kernel Code Exposure in Different Virtualization
Systems}
\label{Reachable-Kernel-Trace-Analysis-for-Different-Virtualization-Systems}

\begin{table}
\centering
\scriptsize
\begin{tabular}{|l|l|l|l|}
  \hline
  \multirow{3}{1.5cm}{\bf Virtualization system} & \multicolumn{3}{c|}{\bf Kernel trace} \\ \cline{2-4}
  & \multirow{2}{1.5cm}{Compared to Native Linux} & \multirow{2}{1.5cm}{In popular paths} & \multirow{2}{1cm}{In risky paths} \\
  & & & \\  \hline
  VirtualBox & 78.8 \% & 46.5 \% & 53.5 \% \\
  \hline
  \multirow{2}{1.5cm}{VMWare Workstation} & \multirow{2}{*}{72.6 \%} &
  \multirow{2}{*}{50.2 \%} & \multirow{2}{*}{49.8 \%} \\
  & & & \\   \hline
  Docker & 61.3 \% & 58.4 \% & 41.6 \% \\
  \hline
  LXC &  65.6\% &  55.7\% &  44.3\% \\
  \hline
   QEMU &  70.1\% & 61.2 \% &  38.8\% \\
  \hline
   KVM &  75.4\% &  57.0\% &  43.0\% \\
  \hline
  Graphene & 49.2 \% & 65.1 \% & 34.9 \% \\
  \hline
  Lind & 36.2 \% & 100 \% & 0 \% \\
  \hline
\end{tabular}
\caption{\small Reachable kernel trace analysis for different virtualization
systems.}
\label{table:trace-systems}
\end{table}

%\textbf{Test Purpose.}
%To determine how much of the underlying kernel can be executed and exposed in
%each system. This helps us understand the potential risks a virtualization system
%may pose based upon how much access it allows to the kernel code.

\noindent
\textbf{Setup.}
%To analyze the reachable kernel paths for each
%virtualization system,
To determine how much of the underlying kernel can be executed and exposed in
each system, 
we conducted system call fuzzing with Trinity (similar to our approach in Section~{\ref{sec.metric}}) to obtain
the kernel trace in each system. This helps us understand the potential risks a virtualization system
may pose based upon how much access it allows to the kernel code.
All experiments were conducted under Linux kernel 3.14.1.

\noindent
\textbf{Results.}
We obtained the total reachable kernel trace for
each tested system,
and further analyzed the components of those traces. These results
are shown in Table \ref{table:trace-systems}.
%
As shown, Lind accessed the least amount of code in the OS
kernel. More importantly, all the kernel code it accessed was in the
popular kernel paths that contain fewer bugs (Section~{\ref{Verification-of-Hypothesis}}).
A large portion of the kernel paths accessed by Lind lie in
\texttt{fs/} to perform file system operations.
In Lind, only basic function calls,
like \texttt{open()}, \texttt{close()}, \texttt{read()}, \texttt{write()}, \texttt{mkdir()},
\texttt{rmdir()}, are allowed. In addition, only commonly used flags are allowed. For example,
only \texttt{O\_CREAT}, \texttt{O\_EXCL}, \texttt{O\_APPEND}, \texttt{O\_TRUNC},
\texttt{O\_RDONLY}, \texttt{O\_WRONLY}, and \texttt{O\_RDWR} are permitted for \texttt{open()}.

The other virtualization systems all accessed a substantial number of code
paths in the kernel,
and they all accessed a larger section of the risky portion.
This is because they have
more dependence on complex system calls, and
allow extensive use of complicated flags. For example,
Graphene provides a complex system call API that allows
\texttt{fork()} and \texttt{signals}, and can access many risky lines of code.
VirtualBox, and therefore VMWare Workstation, and Docker, have even larger
codebases and more complicated system functions. They allow
rarely used flags, such as \texttt{O\_TMPFILE}, \texttt{O\_NONBLOCK},
and \texttt{O\_DSYNC}, which can reach potentially dangerous lines
of code.

To summarize, our analysis suggests that Lind triggers the fewest kernel bugs because
it has better control over the portions of the OS kernel accessed by applications.

\subsection{Impact of Potential Vulnerabilities in Lind's SafePOSIX Construction}
\label{Reachable-Kernel-Trace-Analysis-for-Repy-Sandbox}

%\textbf{Test Purpose.}
%To understand what potential security risks could be posed if Lind's SafePOSIX construction
%has vulnerabilities.

\noindent
\textbf{Setup.}
To understand what potential security risks could be posed if Lind's SafePOSIX construction
has vulnerabilities, we conducted system call fuzzing with Trinity
to obtain the reachable kernel trace in Linux kernel 3.14.1.

\noindent
\textbf{Results.}
An important question about Lind's security properties is what would happen if there is a bug or a failure in Lind's TCB,
the SafePOSIX construction. To understand this, we need to see how much kernel is exposed to 
SafePOSIX. Since our SafePOSIX is entirely built on top of the Repy sandbox kernel, it suffices to see the kernel 
trace of Repy.  

\begin{table}
\centering
\scriptsize
\begin{tabular}{|l|l|l|l|l|}
  \hline
  \multirow{3}{.8cm}{\bf Sandbox} & \multicolumn{4}{c|}{\bf Kernel trace} \\ \cline{2-5}
  & \multirow{2}{1cm}{Compared to Lind} &
  \multirow{2}{1.3cm}{Compared to Native Linux} & \multirow{2}{1.5cm}{In popular paths} &
  \multirow{2}{1.0cm}{In risky paths} \\
  & & & & \\  \hline

  Repy & 105.8 \% & 38.3 \% & 100 \%  & 0 \%  \\
  \hline
\end{tabular}
\caption{\small Comparison of reachable kernel traces within Repy sandbox kernel and Native Linux.}
\label{table:trace-Repy}
\end{table}

The results are shown in Table \ref{table:trace-Repy}. 
The trace of Repy is slightly larger (5.8\%) than that of Lind.
Repy's design do not allow attackers or bugs to
have more access to the risky paths in the OS kernel, and only a small amount (5.8\%) of
additional common paths in the OS kernel is open.
Those new kernel paths are added because some functions in Repy
have more capabilities for message sending and network connection than the system call interfaces
in Lind. For example, in Repy,
\texttt{sendmessage()} and \texttt{openconnection()}
functions could reach out to more lines of code when fuzzed. However, the kernel
 trace of Repy still lies completely within the safe
portion of the OS kernel.
Since the safe portion contains fewer kernel bugs, the Repy sandbox kernel
will have a very slim chance to trigger OS kernel bugs.

The results above show that even if our Repy sandbox kernel has a
bug or failure,
it only slightly increases the amount of OS kernel paths open to attacks,
and all these paths accessed are still inside the safe portion.
Therefore, Repy will not grant attackers more opportunities to trigger OS
kernel bugs.
Since Repy, arguably the main security weakness of the system, can be
considered safe through our analysis,
it shows that Lind has the potential to provide strong security to run user applications.
\yanyan{This paragraph does not feel strong..}

\subsection{Performance Overhead Evaluation}
\label{Performance-Evaluation}

%\textbf{Test Purpose.}
%To measure Lind's runtime performance overhead compared to Native Linux
% when running real-world applications.
%Note that the performance of Lind was not optimized in any way before running
%these tests.

\noindent
\textbf{Setup.}
%To test the execution time overhead in Lind for running real-world applications,
To measure Lind's runtime performance overhead compared to Native Linux
 when running real-world applications, 
we first compiled and ran six widely-used legacy applications:
a prime number calculator Primes version 1.0,
GNU Grep version 2.9, GNU Wget version 1.13, GNU Coreutils version 8.9,
GNU Netcat version 0.7.1, and K\&R Cat. Note that the performance of Lind 
was not optimized in any way before running these tests.

All applications ran unaltered and correctly in Lind. The source code of each application remained
unmodified. To run the applications, it was sufficient to just recompile the
source code using NaCl's compiler and Lind's \texttt{glibc} to call
into SafePOSIX.

In addition, we ran two large legacy applications, Tor version 0.2.3 and Apache version 2.0.64 in Lind.
%Both Tor and Apache were recompiled with NaCl's compiler and ran in Lind.
We used Tor's built-in benchmark program and Apache benchmarking tool \texttt{ab} to perform
basic testing operations and record the execution time.

\begin{table}
\centering
\scriptsize
\begin{tabular}{|r|r|r|r|}
  \hline
  {\bf Application} & {\bf Native Code} & {\bf Lind} & {\bf Impact}  \\
  \hline
  Primes & 10000 ms & 10600 ms & 1.06x \\
  GNU Grep & 65 ms & 260 ms & 4.00x \\
  GNU Wget & 25 ms & 96 ms & 3.84x \\
  GNU Coreutils & 275 ms & 920 ms & 3.35x \\
  GNU Netcat & 780 ms & 2180 ms & 2.79x \\
  K\&R Cat & 20 ms & 125 ms & 6.25x \\
  \hline
\end{tabular}
\caption{\small Execution time performance results on six real-world applications: Native
Linux vs. Lind.}
\label{table:performance_apps}
\end{table}

\noindent
\textbf{Results.}
Table \ref{table:performance_apps} shows the runtime performance
for the six real-world applications mentioned above.
The Primes application run in Lind has a 6\% performance overhead compared to
Native Linux. CPU bound applications, like the Primes, engender little overhead,
because they run only in the NaCl computation sandbox. No system calls are required,
and there is no need to go through the SafePOSIX interface. The small amount of overhead
is generated by NaCl's instruction alignment at building time. Another reason for the overhead
is that the instructions built by NaCl have a higher rate of cache misses, which can slowdown the
program. We expect other CPU bound processes to behave similarly.

The other five applications experienced slowdowns roughly ranging from 3x to 6x.
Since they are all I/O heavy applications,
each repeatedly calls into SafePOSIX that reimplements
the call.  The additional computation of SafePOSIX produced the additional
overhead. It should be noted that for the six applications that we tested, even
with the current overhead, Lind managed to control the performance slowdown to a
 level that is barely noticeable to the users.
The fact that the total execution time was limited to the magnitude of 10000 ms ensures that
user experience is still good.

\begin{table}
\centering
\scriptsize
\begin{tabular}{|r|r|r|r|}
  \hline
  {\bf Benchmark} & {\bf Native Code} & {\bf Lind} & {\bf Impact}  \\
  \hline
  Digest Tests: & & & \\
  Set & 54.80 nsec/element & 176.86 nsec/element & 3.22x \\
  Get & 42.30 nsec/element & 134.38 nsec/element & 3.17x \\
  Add & 11.69 nsec/element & 53.91 nsec/element & 4.61x \\
  IsIn & 8.24 nsec/element & 39.82 nsec/element & 4.83x \\
  \hline
  AES Tests: & & & \\
  1 Byte & 14.83 nsec/B & 36.93 nsec/B & 2.49x \\
  16 Byte & 7.45 nsec/B & 16.95 nsec/B & 2.28x \\
  1024 Byte & 6.91 nsec/B & 15.42 nsec/B & 2.23x \\
  4096 Byte & 6.96 nsec/B & 15.35 nsec/B & 2.21x \\
  8192 Byte & 6.94 nsec/B & 15.47 nsec/B & 2.23x \\
  Cell Sized & 6.81 nsec/B & 14.71 nsec/B & 2.16x \\
  \hline
  Cell Processing: & & & \\
  Inbound & 3378.18 nsec/cell & 8418.03 nsec/cell & 2.49x \\
  (per Byte) & 6.64 nsec/B & 16.54 nsec/B & - \\
  Outbound & 3384.01 nsec/cell & 8127.42 nsec/cell & 2.40x \\
  (per Byte) & 6.65 nsec/B & 15.97 nsec/B & - \\
  \hline
\end{tabular}
\caption{\small Performance results on Tor's built-in benchmark program: Native
Linux vs. Lind.}
\label{table:performance_tor}
\end{table}

A summary of the results for Tor is shown in Table \ref{table:performance_tor}. The
benchmarks focus on cryptographic operations,
which are CPU intensive, but also make system calls like \texttt{getpid}, and reads to
\texttt{/dev/urandom}.
The digest operations time the access of a map of message digests.
The AES operations time AES encryptions of several sizes and message
digest creation.
Cell processing executes full packet encryption and decryption. In our
test, Lind slowed down these operations by 2.5x to 5x. We believe these
slowdowns are due to the increased code size produced by NaCl,
%\cappos{I'm not sure why this would be.  Does NaCl show this too?}
and the increased overhead from Lind's SafePOSIX system call interface.

Results for the Apache benchmarking tool \texttt{ab} is presented in Table \ref{table:performance_apache}.
In the set of experiments, Lind produced a performance slowdown that roughly
ranged from 2x to 9.2x. Most of the overhead was incurred due to system call operations inside the
SafePOSIX construction.

As shown above, Lind generally incurs some performance overhead.
However, performance slowdown is common in virtualization systems.
For example, Graphene \cite{Graphene-14} also shows an overhead ranged from
40\% to 2x, when running applications such as Apache and UNIX benchmark.
Lind shares the same magnitude of slowdown with Graphene in many cases.
Since an attack on the kernel can have devastating
consequences, %at this initial stage,
a tradeoff between security and performance could be justified.
The fact that Lind is able to run
%\cappos{4 applications isn't many...
%Do we have Apache numbers or something else to quantify?}
%\yiwen{I am looking at more apps and libs that we can run and test in Lind.}
legacy applications
suggests that it
is a positive step towards building new secure systems, which will likely become
more efficient as designs become more sophisticated. \yanyan{optimized?}

\begin{table}
\centering
\scriptsize
\begin{tabular}{|r|r|r|r|}
  \hline
  {\bf \# of Requests} & {\bf Native Code} & {\bf Lind} & {\bf Impact}  \\
  \hline
  10 & 900 ms & 1700 ms & 1.89x \\
  20 & 1600 ms & 5000 ms & 3.13x \\
  50 & 4800 ms & 30000 ms & 6.25x\\
  100 & 10000 ms & 92000 ms & 9.20x\\
  \hline
\end{tabular}
\caption{\small Performance results on Apache benchmarking tool \texttt{ab}: Native
Linux vs. Lind.}
\label{table:performance_apache}
\end{table}