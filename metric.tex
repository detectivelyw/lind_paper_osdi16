\section{Developing and Assessing a Quantitative Evaluation Metric for Kernel Security}
\label{sec.metric}

As mentioned in the previous section, one problem in the development of kernel
security systems is the lack of reliable quantitative metrics that
can accurately identify portions of the OS kernel with the highest potential
to unleash inherent bugs. By understanding how and when
a line of code in the kernel is used, down to the level of lines of code, we
should be able to predict its likelihood to contain a security flaw, and thus
design a secure system to prevent its exploitation.
In this section, we document the formulation and testing
of a quantitative evaluation metric for securing the kernel that begins with the
rather simple idea that kernel paths executed by common applications
during everyday use are less likely to contain security flaws. The intuition
is that these code paths are very well-tested due to their constant use, and
thus it is much less likely that security bugs will occur in these lines of code.
Our initial testing of this premise yielded promising results, with only one
bug appearing in these popular paths.  We also compare the performance of our
new metric against two earlier works that offered methods to predict bug
locations in software.

\subsection{Experiment Setup}
To test our metric we performed an analysis of two different versions of
the Linux kernel, 3.13.0 and 3.14.1. Since our findings for these
versions are quantitatively and qualitatively similar, we report
the results for 3.13.0 in this section and use 3.14.1 in Section~\ref{sec.evaluation}. 
We used two different versions of Linux kernel, because we want to first establish 
the foundation of our new design with one dataset, and then evaluate the prototype 
system that comes from our design with a different dataset. The two different datasets 
form a cross validation, which makes sure that our evaluation is not biased. In addition, 
evaluation with two different kernel versions shows that our design is not a specifically 
tailored solution for just one version, but rather a general solution that could be useful 
for multiple versions of the kernel. 

To trace the kernel, we used \texttt{gcov}~\cite{gcov}. A standard utility with
the GNU compiler collection (GCC) suite,
\texttt{gcov} is a program profiling tool that indicates which lines of kernel
code are executed while an application runs. 

\textbf{Commonly-used kernel paths.}
To capture the commonly-used kernel paths, we used two strategies concurrently.
First, we attempted to capture the normal usage behavior of popular applications.
To do this, two students used applications in the 50 most popular Debian
packages~\cite{Top-Packages}(omitting libraries) for Debian 7.0, which is a widely-used and 
popular open source project. 
Each student used 25 applications for their designed
tasks (i.e., writing, spell checking, and then printing a letter in a text
editor, or recoloring and adding a caption to a picture in image processing
software). In instances where there were two applications that performed a
similar task (i.e., Mozilla Firefox and Google Chrome), both programs were
used. These tests were completed over 20 hours of
total use over 5 calendar days. 

The second strategy was to try to capture the total range of usages for an
individual computer user. Hence, the students used the workstation as their
desktop machine for a one week period. They did their homework, developed
software, communicated with friends and family, etc., using this system.
Software was installed as needed.

Using these two strategies, we obtained a profile of the lines of
kernel code (publicly available at~\cite{Lind}), that indicate
a set of commonly-used kernel paths.

\textbf{Locating bugs.}
Having identified the kernel paths used during application execution, we next
addressed how bugs are distributed in these paths. We collected a list of
severe kernel bugs from the National Vulnerability Database~\cite{NVD}. 
For each bug, we found the patch that fixed the problem and identified
which lines of kernel code were modified to remove it.
For the purpose of this study, a user program that can execute a line of kernel
code changed by such a patch is considered to have the \textit{potential to
exploit that flaw}.  Note, it is possible that in some situations this may
overestimate the ability for an attacker to exploit a flaw, since it may be
possible that additional lines of code must also be executed to trigger the flaw.


\subsection{Results and Analysis}
\label{Verification-of-Hypothesis}

After examining the set of lines that were patched to fix bugs and the traces for
the commonly-used kernel paths, we found that only one of the 40 kernel bugs
was found within the popular paths, even though these paths make up 12.4\% of the kernel 
(Figure \ref{fig:coverage}). 
To verify the statistical significance of these results, we performed a power
analysis utilizing a Poisson distribution, a form of probability analysis to express the
likelihood of a given number of events occurring in a fixed interval of time
and/or space.

We assume that kernel bugs appear at an average rate proportional to the
number of lines of kernel code, and independently of the time since the last
bug occurrence. Therefore, the rate of defect occurrence per LOC does
follow a Poisson distribution~\cite{Poisson-distribution}.
This is consistent with the work of Mayer, et. al.~\cite{mayer1989probability}, who
proposed a probability model for characterizing the relationship between discrete
data set.
The basic premise we tested is that bugs occur at different rates in different
parts of the kernel,
i.e., the less popular portion has more bugs. Without
loss of generality, we assume that the kernel can be divided into two sections,
$A$ and $B$, where bugs occur at rates $\lambda_A$ and
$\lambda_B$, and $\lambda_A \neq \lambda_B$. Given the null-hypothesis
that the rate of defect occurrences is the \textit{same} in set $A$ and $B$
(or bugs in $A$ and $B$ are drawn from the same Poisson distribution),
we used the Uniformly Most Powerful Unbiased (UMPU) test~\cite{shiue1982experiment}
to compare unequal-sized code blocks.
At a significance level of $\alpha=0.01$, the test was significant at
$\rho=0.0015$, rejecting the null-hypothesis.
The test also reported a 95\% confidence interval that $\lambda_A / \lambda_B
\in [0.002, 0.525]$. This indicates that ratios between bug-rates in each set are well
below 1, and $B$ is the risky set that tends to have more bugs.
In our study, set A represents the commonly used paths in the kernel, while set B
represents the uncommonly used paths. The above statistical results show that
set A has a much lower bug rates than set B, which means that the popular kernel paths
contain much fewer bugs. Our metric is thus effective in locating bugs in the Linux kernel.

\textbf{Comparison with other metrics.}
As we have already stated, we are not the first to propose a metric for judging
which sections of kernel code may be buggy.
Many of the previous attempts work at a coarser granularity (e.g., at file level)
than our work that focuses on
individual lines of code. This is particularly key because, when run at a file
granularity, we found that even commonly used programs used parts of
32 files that contained flaws. In fact, common
programs executed 36 functions that were later patched to fix security
flaws, indicating the need to better localize bugs. 

Earlier work by Ozment, et al.~\cite{ozment2006milk} demonstrated that code that
had been around longer in the BSD kernel tended to have fewer bugs.
They determined that a significant extent (61\%) of the reported
vulnerabilities were ``foundational," meaning they were introduced prior to the
initial version studied. They also reported these vulnerabilities
have a median lifetime of at least 2.6 years.
We used their metric on our Linux kernel code and our 40 bug dataset.
To follow this age-based metric, we put the Linux kernel code into five different age groups. 
Our results (Figure \ref{fig:metrics_age}) showed that there is a substantial number of bugs located 
within each age group. No evident cluster patterns among bugs in any particular age group could be identified. 
This suggests that buggy code in the Linux kernel cannot be identified effectively
by simply using this age-based metric.

Chou, et al.~\cite{PittSFIeld} showed that certain parts of the kernel
were more vulnerable than others. In particular, he identified device drivers as
have much higher error rates than those in other parts of the kernel.
Applying this metric on our dataset, we found that the driver code in our version
of the Linux kernel accounted for only 8.9\% of the total codebase, and contained
merely 4 out of the 40 bugs (Figure \ref{fig:metrics_drivers}). 
Using this metric also proves to be difficult with the
Linux kernel, since our results show that
only 10.0\% of the kernel bugs could be detected.

However, this led us to consider that perhaps since drivers are not used
in many scenarios, code that is unreachable in some situations may have a
different vulnerability profile.  To test this, we
further examined the reachable lines of
code within the kernel using two techniques. First,
we performed system call fuzzing experiments with the Trinity
system call fuzz tester~\cite{Trinity}. These included 16 child processes
(Trinity workers) executing each Linux system call with 1 million iterations.
Second, we used the Linux Test Project (LTP)~\cite{LTP}, a test suite written
using detailed kernel knowledge. This test suite is meant to exercise the
existing Linux system call interface to
test its correctness, robustness, and performance impact.

The (primarily) black box fuzzing technique from Trinity and test suite of
LTP combined to reach 44.6\% of the kernel, including all 12.4\% of the common
paths.  The security in the reachable portion is actually
slightly higher than the unreachable portion. This is true despite
approximately 1/3 of this code, the commonly-used paths, only containing
a single flaw. This means that the rate of bug occurrence in reachable, but
not commonly-used kernel paths, is actually higher than that in unused
code. We speculate that this may be because of a higher rate of bug discovery
in code that is available to execute in diverse configurations.

To summarize, we demonstrated that the metric of looking at commonly-used
kernel paths provides a statistically significant ($\alpha=0.01$,
$\rho=0.0015$) means for predicting where in the kernel exploitable flaws
will be found in the future.  For the remainder of the paper, we will
focus on using this result to build more secure systems.

\begin{figure}
\centering
\includegraphics[width=1.0\columnwidth]{diagram/kernel_coverage.png}
\caption{\small Percentage of different kernel areas that were reached during
 LTP and Trinity system call fuzzing experiments, with the zero-day kernel bugs identified
 in each area.}
\label{fig:coverage}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=1.0\columnwidth]{diagram/metrics_age.png}
\caption{\small Bug distribution with Ozment's metric \cite{ozment2006milk}.}
\label{fig:metrics_age}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=0.9\columnwidth]{diagram/metrics_drivers.png}
\caption{\small Bug distribution with Chou's metric \cite{PittSFIeld}.}
\label{fig:metrics_drivers}
\end{figure}