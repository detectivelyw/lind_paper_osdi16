\section{Design Options for Secure Virtualization Systems}
\label{sec.design}

Providing essential system functionality without exposing privileged code is one of the
primary challenges. 
Currently, there are two basic approaches.
One, called ``System Call Interposition (SCI)," checks and passes system calls
through to the underlying kernel. The other, known as ``functionality
reimplementation," requires rebuilding system functionality with new code. In the
following, we show that both methods are limited in their ability to
prevent attacks in the kernel. 
With our metric in Section~\ref{sec.metric}, 
we propose a new design scheme named ``Lock-in-Pop" that combines safer reimplementation
within a secure environment, and accesses only popular code requests through a
very small trusted computer base.


\subsection{System Call Interposition (SCI)}
SCI is the long-standing idea behind sandboxing systems like Janus
\cite{Janus0:96, Janus:99}. It relies on the underlying kernel
to provide system functionality. To prevent attackers from undermining the system,
SCI uses a system call filter module to mediate requests
from untrusted user code instead of allowing it to go directly to the kernel.
The filter will check a predefined security policy to decide which system calls are
allowed to pass to the underlying kernel, and which ones must be stopped.
Figure \ref{fig:design_system_call_interposition} illustrates the general design
of a system call interposition system. System administrators have direct access to 
setting and changing the security policies through a policy engine module. 
This key part of the system would pose great threat if compromised, thus making it 
one component of the trusted computing base. 

\begin{figure}%[h]
\centering
\includegraphics[width=1.0\columnwidth]{diagram/Virtualization_Design_Model_03.png}
\caption{\small Schematic of System Call Interposition.}
\label{fig:design_system_call_interposition}
\end{figure}  

System call interposition was once a popular approach to the design of secure
virtualization systems because it gave developers the power to set and enforce
security policies. 
\lois{I think I asked this during the last revision. You say ``was"
a popular approach. Is it not a popular approach anymore?}
\yiwen{It is not a popular approach anymore, since no modern design could simply rely on 
this idea to build practical system.}
However, this design
is limited by its overly complicated approach to policy decisions and implementation.
To make a policy decision, the system needs to
obtain and interpret the OS state (permissions, user groups, register flags, and etc.) 
associated with the programs it is monitoring.
The complexity of OS states makes this process difficult and can lead to
inaccurate policy decisions.
Second, there are many indirect paths in the kernel that can be accessed.
Overlooking those paths by security policy makers would render the
system call interposition policy ineffective, because attackers will be able to
bypass the imposed security checks. 
Moreover, many side-effects of blocking
certain system calls could affect the function of desired system calls.
It is difficult for developers to fully understand the side-effects of all the
system calls in an interface as complex as the UNIX API. 
For example, many applications that rely on \texttt{setuid} fail to check its return value. 
And if \texttt{setuid} call is blocked and fails, those applications will continue to function in a compromised state, 
with incorrect permissions and privileges. 
Therefore, it would be very challenging to design and build a secure virtualization system using
system call interposition alone.

\subsection{Functionality Reimplementation}
Systems such as  Drawbridge \cite{Drawbridge-11},
 Bascule \cite{Bascule}, and Graphene \cite{Graphene-14} can
provide richer functionality and run complex programs than most systems built
with SCI alone. These systems have their own system
interfaces and libraries. Some virtualization
systems, such as OS VM systems VirtualBox, and VMWare Workstation, even have the
full functionality of an OS reimplemented in their codebase. We call such a design
``functionality reimplementation."

\begin{figure}%[h]
\centering
\includegraphics[width=1.0\columnwidth]{diagram/Virtualization_Design_Model_02.png}
\caption{\small Schematic of Functionality reimplementation System.}
\label{fig:design_functionality_reimplementation}
\end{figure}

The key idea of this design is to not fully rely on the underlying
kernel for system functions. Instead, critical OS functions are re-written with new
code. As illustrated in Figure \ref{fig:design_functionality_reimplementation}, 
this design scheme reimplements its own system functionality to provide to user code. 
When it has to communicate with the kernel 
to access resources like memory, CPU, and disk storage, the system will do so with
its underlying TCB code, which can access the kernel directly.
For example, Graphene \cite{Graphene-14} reimplements
its own Linux system calls in the
\texttt{libLinux.so} module. When it needs to acquire resources from
the kernel, it uses a
Platform Adaptation Layer (PAL)  module that has access to the kernel
and provides basic ABI functions to the OS library.

Functionality reimplementation provides a more realistic solution to building
virtualization systems than earlier efforts, and offers rich functionality.
However, hundreds of vulnerabilities in existing virtualization systems have still been
reported over the past ten years ~\cite{NVD}. One shortcoming of such a system is the size
of the implemented components. To provide rich functions, systems using this design have
introduced larger codebases and increased the size of their TCBs. In addition, the
complex semantics of OS functions can easily result in bugs and vulnerabilities in
reimplementation. Some vulnerabilities
will directly cause a privilege escalation, which allows attackers to escape the sandbox
and execute arbitrary code on the host OS. 
For example, a vulnerability in VMWare's codebase caused by buffer overflows in the VIX
API could allow local users to escape out of the guest VM and 
gain privilege escalation to execute arbitrary code in the host
OS, even shellcode to access the kernel of the host OS~\cite{CVE-2008-2100}. 

Even operations that are considered
legal and harmless in the guest OS may open up system call paths into the underlying
host OS and cause a problem.
This type of problem can be fatal, 
as it can reach and trigger vulnerabilities in the underlying OS kernel.

\subsection{Lock-in-Pop: Staying on the Beaten Path }
A common weakness of both of these previous approaches is the inevitable contact
between the privileged code of the kernel and the untrusted application. 
By leveraging our key observation 
that ``popular, frequently-used kernel paths contain fewer bugs" we propose a design
in which all code including the complex part
of the operating system interface should access only
popular kernel paths through a small TCB. As it ``locks" all functionality 
requests into only the ``popular" paths, we thus dubbed the
design ``Lock-in-Pop."

In addition, the system is entirely in the userspace, and both the size of 
the sandbox kernel and its access to the OS kernel is restricted
(Figure \ref{fig:design_safe_reimplementation}). Any complex or possibly risky system
functions that require contact with the OS kernel is reimplemented using
memory-safe code and is contained within a sandbox. This approach has advantages
over the others that require modifications to
the OS kernel (Section {\ref{sec.metric}). The isolation provided by placing
``Lock-in-Pop'' in the userspace is also an added protection over functionality
reimplemention. If a modified module is in the OS kernel and is compromised, it
exposes kernel privileges that could allow attacks 
in the underlying system and any applications in the userspace.

As shown in Figure \ref{fig:design_safe_reimplementation}, the key to our 
``Lock-in-Pop'' design is to construct a safe system function reimplementation within 
the library OS sandbox. 
The library OS sandbox responds to the system call requests and
returns results to the user code, if the requests are granted.
It is comprised of two parts: a sandbox kernel that provides access to basic but critical
system calls, and a system functionality safe reimplementation that implements more
complex calls, such as file system calls. 
The sandbox kernel forms the only TCB of our library OS, and is kept
extremely small and simple so that it is easy to verify its security.
The sandbox code provides an API that performs a few critical system calls with
the most basic parameters, such as writing data to the file system
and communicating with the network. The kernel utilizes the most simplistic calls
possible with the most basic arguments. The system functionality safe reimplementation 
is then built on top of the sandbox kernel. One important design rule is to only rely on the 
sandbox kernel API when trying to acquire hardware resources from the underlying OS kernel. 
The safe reimplementation will then use those basic resources, such as memory allocations, 
network sockets, and file descriptors to construct a virtual system interface, which will be 
provided to untrusted user code. 

\begin{figure}%[h]
\centering
\includegraphics[width=1.0\columnwidth]{diagram/Virtualization_Design_Model_01.png}
\caption{\small ``Lock-in-Pop''System ensures safe execution of untrusted user code
despite existing potential zero-day bugs in the OS kernel.}
\label{fig:design_safe_reimplementation}
\end{figure}

With the system functionality safe reimplementation, unmodified user code is able to run on top of our designed system.
It is important to note that our design does not rely on any specific technique or tool, and it is possible
to choose from several different techniques that fit specific security requirements.
The following section describes one possible implementation of our design called Lind.